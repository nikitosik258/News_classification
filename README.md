# News Classification

## Задача
Классификация новостей

## Данные
- **Источник:** Описания вакансий с различных job-сайтов. Можно скачать по ссылке: https://disk.yandex.ru/d/l068c8NnHpY02w
- **Размер:** 120 000 новостей
- **Признаки:**
  - `Title` - заголовок новости
  - `Description` - описание новости
- **Целевая переменная:** `Class Index`  (1 — World/Politics, 2 — Sports, 3 — Business, 4 — Sci/Tech)

## Решение

### 1. EDA (главные выводы)
- Обнаружены дубликаты текстов (одни и те же Description с разным Title)
- Обнаружены мусорные записи (например, #NAME?, HTML-артефакты вида #39; одиночные символы s, t и т.д.)
- Все классы сбалансированные

### 2. Baseline модели
- **CountVectorizer + классические ML алгоритмы:**
  - LogisticRegression
  - DecisionTreeClassifier  
  - RandomForestClassifier
  - LGBMClassifier
- **TF-IDF векторизация**
- **Очистка данных:** удаление стоп-слов
- **Метрики:** использовалось Macro усреднение

**Выводы**
- CountVectorizer с удалением стоп-слов метрики особо не меняет, но уменьшает время обучения.
- Отбор важных токенов помогает только линейным моделям, но замедляет обучение
- **Результаты CountVectorizer с удалением стоп-слов :**
  <img width="1135" height="580" alt="image" src="https://github.com/user-attachments/assets/d0224b86-bdd3-48a1-9308-e23f6849af73" />


### 3. Нейронные сети
- **При решениии использовался PyTorch**
- **RNN** - рекуррентная сеть для анализа последовательностей
- **CNN** - сверточная сеть для выявления локальных паттернов
- **LSTM** - долгосрочная память для сложных зависимостей
- **CNN + GloVe** - предобученные эмбеддинги слов

### 4. Предобработка
- Токенизация с помощью word-level
- Создание последовательностей для нейронных сетей
- Отбор важных токенов
- Стратифицированная кросс-валидация

## Итоговые метрики:
<img width="1127" height="586" alt="image" src="https://github.com/user-attachments/assets/b6d34763-0845-4932-91aa-17ae27c5d634" />
